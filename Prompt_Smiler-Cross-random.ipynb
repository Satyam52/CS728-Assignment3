{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slhich8eu-ps",
    "outputId": "8d9daa68-a661-46e9-82ad-7059b99e51a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "p7zip is already the newest version (16.02+dfsg-8).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# !apt-get install p7zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNqK7iJ4r78m",
    "outputId": "07fcdfed-7318-4b7e-8744-d81c8ece41a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-02 05:11:16--  https://github.com/samsungnlp/smiler/raw/main/smiler_corpora_v1.0_part1.7z\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/samsungnlp/smiler/main/smiler_corpora_v1.0_part1.7z [following]\n",
      "--2024-05-02 05:11:16--  https://raw.githubusercontent.com/samsungnlp/smiler/main/smiler_corpora_v1.0_part1.7z\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28929993 (28M) [application/octet-stream]\n",
      "Saving to: ‘smiler_corpora_v1.0_part1.7z’\n",
      "\n",
      "smiler_corpora_v1.0 100%[===================>]  27.59M  11.5MB/s    in 2.4s    \n",
      "\n",
      "2024-05-02 05:11:19 (11.5 MB/s) - ‘smiler_corpora_v1.0_part1.7z’ saved [28929993/28929993]\n",
      "\n",
      "/bin/bash: line 1: 7z: command not found\n"
     ]
    }
   ],
   "source": [
    "# !wget https://github.com/samsungnlp/smiler/raw/main/smiler_corpora_v1.0_part1.7z\n",
    "# !7z e smiler_corpora_v1.0_part1.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vGLsDYBcAQhU"
   },
   "outputs": [],
   "source": [
    "SMILER_TRANSLATE = {\n",
    "    \"en\": {\n",
    "        \"birth-place\": \"birth place\",\n",
    "        \"eats\": \"eats\",\n",
    "        \"event-year\": \"event year\",\n",
    "        \"first-product\": \"first product\",\n",
    "        \"from-country\": \"from country\",\n",
    "        \"has-author\": \"has author\",\n",
    "        \"has-child\": \"has child\",\n",
    "        \"has-edu\": \"has education\",\n",
    "        \"has-genre\": \"has genre\",\n",
    "        \"has-height\": \"has height\",\n",
    "        \"has-highest-mountain\": \"has highest mountain\",\n",
    "        \"has-length\": \"has length\",\n",
    "        \"has-lifespan\": \"has lifespan\",\n",
    "        \"has-nationality\": \"has nationality\",\n",
    "        \"has-occupation\": \"has occupation\",\n",
    "        \"has-parent\": \"has parent\",\n",
    "        \"has-population\": \"has population\",\n",
    "        \"has-sibling\": \"has sibling\",\n",
    "        \"has-spouse\": \"has spouse\",\n",
    "        \"has-tourist-attraction\": \"has tourist attraction\",\n",
    "        \"has-type\": \"has type\",\n",
    "        \"has-weight\": \"has weight\",\n",
    "        \"headquarters\": \"headquarters\",\n",
    "        \"invented-by\": \"invented by\",\n",
    "        \"invented-when\": \"invented when\",\n",
    "        \"is-member-of\": \"is member of\",\n",
    "        \"is-where\": \"located in\",\n",
    "        \"loc-leader\": \"location leader\",\n",
    "        \"movie-has-director\": \"movie has director\",\n",
    "        \"no_relation\": \"no relation\",\n",
    "        \"org-has-founder\": \"organization has founder\",\n",
    "        \"org-has-member\": \"organization has member\",\n",
    "        \"org-leader\": \"organization leader\",\n",
    "        \"post-code\": \"post code\",\n",
    "        \"starring\": \"starring\",\n",
    "        \"won-award\": \"won award\",\n",
    "    },\n",
    "    \"fr\": {\n",
    "        \"birth-place\": \"lieu de naissance\",\n",
    "        \"eats\": \"mange\",\n",
    "        \"event-year\": \"année de l'événement\",\n",
    "        \"first-product\": \"premier produit\",\n",
    "        \"from-country\": \"du pays\",\n",
    "        \"has-author\": \"a pour auteur\",\n",
    "        \"has-child\": \"a pour enfant\",\n",
    "        \"has-edu\": \"a une éducation\",\n",
    "        \"has-genre\": \"a un genre\",\n",
    "        \"has-height\": \"a une taille\",\n",
    "        \"has-highest-mountain\": \"a la plus haute montagne\",\n",
    "        \"has-length\": \"a une longueur\",\n",
    "        \"has-lifespan\": \"a une durée de vie\",\n",
    "        \"has-nationality\": \"a une nationalité\",\n",
    "        \"has-occupation\": \"a une occupation\",\n",
    "        \"has-parent\": \"a un parent\",\n",
    "        \"has-population\": \"a une population\",\n",
    "        \"has-sibling\": \"a un frère ou une sœur\",\n",
    "        \"has-spouse\": \"a un conjoint\",\n",
    "        \"has-tourist-attraction\": \"a une attraction touristique\",\n",
    "        \"has-type\": \"a un type\",\n",
    "        \"has-weight\": \"a un poids\",\n",
    "        \"headquarters\": \"siège social\",\n",
    "        \"invented-by\": \"inventé(e) par\",\n",
    "        \"invented-when\": \"inventé(e) quand\",\n",
    "        \"is-member-of\": \"est membre de\",\n",
    "        \"is-where\": \"est situé(e) à\",\n",
    "        \"loc-leader\": \"leader local\",\n",
    "        \"movie-has-director\": \"film réalisé par\",\n",
    "        \"no_relation\": \"aucune relation\",\n",
    "        \"org-has-founder\": \"organisation fondée par\",\n",
    "        \"org-has-member\": \"organisation a pour membre\",\n",
    "        \"org-leader\": \"leader de l'organisation\",\n",
    "        \"post-code\": \"code postal\",\n",
    "        \"starring\": \"mettant en vedette\",\n",
    "        \"won-award\": \"a remporté un prix\"\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"birth-place\": \"место рождения\",\n",
    "        \"eats\": \"ест\",\n",
    "        \"event-year\": \"год события\",\n",
    "        \"first-product\": \"первый продукт\",\n",
    "        \"from-country\": \"из страны\",\n",
    "        \"has-author\": \"имеет автора\",\n",
    "        \"has-child\": \"имеет ребенка\",\n",
    "        \"has-edu\": \"имеет образование\",\n",
    "        \"has-genre\": \"имеет жанр\",\n",
    "        \"has-height\": \"имеет рост\",\n",
    "        \"has-highest-mountain\": \"имеет самую высокую гору\",\n",
    "        \"has-length\": \"имеет длину\",\n",
    "        \"has-lifespan\": \"имеет продолжительность жизни\",\n",
    "        \"has-nationality\": \"имеет национальность\",\n",
    "        \"has-occupation\": \"имеет профессию\",\n",
    "        \"has-parent\": \"имеет родителя\",\n",
    "        \"has-population\": \"имеет население\",\n",
    "        \"has-sibling\": \"имеет брата или сестру\",\n",
    "        \"has-spouse\": \"имеет супруга(у)\",\n",
    "        \"has-tourist-attraction\": \"имеет туристическую достопримечательность\",\n",
    "        \"has-type\": \"имеет тип\",\n",
    "        \"has-weight\": \"имеет вес\",\n",
    "        \"headquarters\": \"штаб-квартира\",\n",
    "        \"invented-by\": \"изобретен(а) кем\",\n",
    "        \"invented-when\": \"изобретен(а) когда\",\n",
    "        \"is-member-of\": \"является членом\",\n",
    "        \"is-where\": \"находится в\",\n",
    "        \"loc-leader\": \"лидер местности\",\n",
    "        \"movie-has-director\": \"фильм имеет режиссера\",\n",
    "        \"no_relation\": \"нет отношения\",\n",
    "        \"org-has-founder\": \"организация имеет основателя\",\n",
    "        \"org-has-member\": \"организация имеет члена\",\n",
    "        \"org-leader\": \"лидер организации\",\n",
    "        \"post-code\": \"почтовый индекс\",\n",
    "        \"starring\": \"с участием\",\n",
    "        \"won-award\": \"получил(а) награду\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3483365783542bbb7e77d40a2e28ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e63b1d6c1234169a3a549a0de1be182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfda3396074d45c5a92b4eab27e156a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8b447d34074fdabcb9afa9fe7f5f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8ef32340fa4ab49dab6dc88f0697b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666dd08a8ba2493a8efb0bf8c1d3d722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e124208af24623b65e35ac5a43eb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForCausalLM \n",
    "class args:\n",
    "    tgt_num = 200 # First 200 examples from the target language\n",
    "    src_num = 5 # NO examples from the source language\n",
    "    max_new_tokens = 100\n",
    "    temperature = 0.6\n",
    "    device=\"cuda:0\"\n",
    "    l1 = \"en\"\n",
    "    l2 = \"fr\"\n",
    "    l3 = \"ru\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/mt0-xxl\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/mt0-xxl\").to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "cf1d2483bfa940c99cd6d1c1bb2102f4",
      "35ea4b05b4b846dba3ec8f02187bcf74",
      "8abc87c740f843579b5442588ec0310d",
      "687c6b1edf7c4c1f904cf05781bbcb7d",
      "94eb1b7347ff452f80c9065d51073b97",
      "59e0fc85e27943c99a2b5638847162ba",
      "c048ce12b86d43f3a7f73d57206af54b",
      "86a3b5428b6e4cfead4ac4881f3fadc0",
      "e48625d8fd7748f29fc24eff45ebedc7",
      "e00260ebab7a417c8b11a0258be7639e",
      "0117f2e9046345a5b40027edfac7f720"
     ]
    },
    "id": "c4wT1bvnuct_",
    "outputId": "01486540-a8c6-4c0a-c1a6-75725cc8b23c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birth-place birth place\n",
      "has-type located in\n",
      "movie-has-director director\n",
      "has-occupation occupation\n",
      "movie-has-director director\n",
      "birth-place birth place\n",
      "has-genre genre\n",
      "birth-place birth place\n",
      "birth-place country\n",
      "birth-place birth place\n",
      "has-genre genre\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "has-occupation occupation\n",
      "has-type has type\n",
      "birth-place birth place\n",
      "has-author author\n",
      "has-occupation occupation\n",
      "has-occupation occupation\n",
      "from-country birth place\n",
      "birth-place birth place\n",
      "has-type located in\n",
      "birth-place birth place\n",
      "is-where country\n",
      "is-where located in\n",
      "movie-has-director director\n",
      "is-where located in\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "has-author author\n",
      "has-genre genre\n",
      "org-has-member member of\n",
      "has-author author\n",
      "has-occupation occupation\n",
      "event-year inception\n",
      "headquarters located in\n",
      "has-type instance of\n",
      "is-where country\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "has-parent father\n",
      "has-occupation founder\n",
      "movie-has-director author\n",
      "is-where located in\n",
      "is-where located in\n",
      "is-where country\n",
      "birth-place birth place\n",
      "has-genre genre\n",
      "is-where located in\n",
      "is-where country\n",
      "movie-has-director director\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "movie-has-director director\n",
      "is-where country\n",
      "has-occupation occupation\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-author director\n",
      "movie-has-director director\n",
      "from-country country\n",
      "birth-place country\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-type instance of\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "is-member-of member of\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "has-type located in\n",
      "birth-place birth place\n",
      "has-genre genre\n",
      "has-occupation occupation\n",
      "has-genre genre\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "is-where located in\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-occupation occupation\n",
      "has-occupation occupation\n",
      "has-genre genre\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-genre no relation\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place country\n",
      "movie-has-director director\n",
      "has-type instance of\n",
      "has-occupation occupation\n",
      "is-where country\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-author author\n",
      "birth-place birth place\n",
      "is-where country\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-occupation occupation\n",
      "is-where located in\n",
      "has-occupation occupation\n",
      "org-has-member founder\n",
      "birth-place birth place\n",
      "has-type instance of\n",
      "is-where country\n",
      "movie-has-director director\n",
      "from-country birth place\n",
      "has-author no relation\n",
      "birth-place birth place\n",
      "has-type genre\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-type instance of\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-genre genre\n",
      "is-where located in\n",
      "is-where location\n",
      "has-spouse no relation\n",
      "is-where country\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-genre environment\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-occupation occupation\n",
      "from-country country\n",
      "is-member-of member of\n",
      "birth-place birth place\n",
      "has-occupation occupation\n",
      "birth-place birth place\n",
      "has-occupation occupation\n",
      "is-where located in\n",
      "has-type instance of\n",
      "movie-has-director director\n",
      "birth-place birth place\n",
      "has-occupation occupation\n",
      "is-where located in\n",
      "has-occupation occupation\n",
      "movie-has-director director\n",
      "has-genre genre\n",
      "org-has-founder founder\n",
      "is-where country\n",
      "birth-place birth place\n",
      "has-author author\n",
      "has-occupation occupation\n",
      "has-type instance of\n",
      "birth-place birth place\n",
      "movie-has-director director\n",
      "movie-has-director director\n",
      "has-edu no relation\n",
      "has-occupation occupation\n",
      "has-type instance of\n",
      "has-occupation occupation\n",
      "has-occupation occupation\n",
      "has-occupation occupation\n",
      "org-leader leader\n",
      "no_relation no relation\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-type studio\n",
      "is-where located in\n",
      "org-has-founder founder\n",
      "is-where country\n",
      "birth-place birth place\n",
      "has-type instance of\n",
      "birth-place birth place\n",
      "birth-place birth place\n",
      "has-type no relation\n",
      "from-country country\n",
      "is-where located in\n",
      "birth-place birth place\n",
      "from-country birth place\n",
      "is-where located in\n",
      "org-has-member no relation\n",
      "birth-place birth place\n",
      "is-where located in\n",
      "birth-place birth place\n",
      "no_relation no relation\n",
      "is-member-of member of\n",
      "movie-has-director director\n",
      "movie-has-director director\n",
      "movie-has-director director\n",
      "has-occupation organization leader\n",
      "from-country birth place\n",
      "birth-place birth place\n",
      "is-where located in\n",
      "birth-place birth place\n",
      "has-type instance of\n",
      "birth-place birth place\n",
      "is-where country\n",
      "Results saved for en to fr\n",
      "has-occupation no relation\n",
      "has-occupation ас влетс иоисолнител мукалн родсер актр и редринимател\n",
      "has-occupation no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-occupation уран урсун влетс еловееским релиионм критиком и равовм релиионм критиком\n",
      "has-type no relation\n",
      "has-edu no relation\n",
      "has-population no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-type no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "no_relation no relation\n",
      "has-population no relation\n",
      "has-type no relation\n",
      "has-population has population\n",
      "has-type no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-type твердение «мерт на нееса»  — двенадат иод восмоо сеона ританскоо науноантастиескоо телесериала «октор то» \n",
      "has-population no relation\n",
      "has-type no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-type no relation\n",
      "has-occupation улвио рсини и уманист\n",
      "no_relation no relation\n",
      "has-occupation мадо ерво и от\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-population no relation\n",
      "has-genre no relation\n",
      "has-occupation no relation\n",
      "has-occupation ала уди вросла в раоне ордаланн\n",
      "has-population no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-population no relation\n",
      "has-population no relation\n",
      "has-genre no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation has occupation\n",
      "has-occupation has occupation\n",
      "has-occupation has occupation\n",
      "has-type no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-occupation has occupation\n",
      "has-population no relation\n",
      "has-genre no relation\n",
      "has-type no relation\n",
      "has-type алери ковски слева и имунд ен осле риемлени 1978\n",
      "has-population no relation\n",
      "event-year no relation\n",
      "has-occupation has occupation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-type no relation\n",
      "has-occupation has occupation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-type no relation\n",
      "has-occupation no relation\n",
      "has-occupation насио оронел илреал илреал насио оронел илреал наркоарон\n",
      "has-population no relation\n",
      "has-genre no relation\n",
      "has-occupation no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-occupation реер влетс анлиским актр ивестн россиским рителм реде всео каитана астинса в телесериале «уаро ат ристи» и ер\n",
      "has-occupation no relation\n",
      "has-type no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-type no relation\n",
      "has-occupation has occupation\n",
      "has-type no relation\n",
      "has-type no relation\n",
      "has-population no relation\n",
      "event-year 2004\n",
      "has-occupation no relation\n",
      "no_relation no relation\n",
      "has-genre аоло одо и тено\n",
      "has-occupation has occupation\n",
      "has-type тан уровника\n",
      "has-occupation no relation\n",
      "has-occupation has occupation\n",
      "has-type ород од наванием илосердие\n",
      "has-population no relation\n",
      "has-type no relation\n",
      "has-occupation no relation\n",
      "has-genre no relation\n",
      "has-type no relation\n",
      "has-type no relation\n",
      "event-year no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-occupation has occupation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-occupation no relation\n",
      "has-genre no relation\n",
      "has-occupation no relation\n",
      "has-genre no relation\n",
      "has-population no relation\n",
      "has-occupation no relation\n",
      "has-type риород идне\n",
      "has-occupation has occupation\n",
      "has-population no relation\n",
      "has-occupation и иллер\n",
      "has-population has population\n",
      "has-occupation no relation\n",
      "Results saved for en to ru\n",
      "has-type instance of\n",
      "from-country country of citizenship\n",
      "is-where country\n",
      "birth-place place of birth\n",
      "is-where located in the administrative territorial entity\n",
      "is-where country of origin\n",
      "org-has-member musician\n",
      "birth-place place of birth\n",
      "from-country country of citizenship\n",
      "has-type instance of\n",
      "has-author author\n",
      "birth-place country of citizenship\n",
      "birth-place country of citizenship\n",
      "is-where country\n",
      "is-where located in the administrative territorial entity\n",
      "has-author author\n",
      "movie-has-director director\n",
      "headquarters located in the administrative territorial entity\n",
      "headquarters country\n",
      "has-author author\n",
      "headquarters country\n",
      "is-where country\n",
      "has-occupation occupation\n",
      "has-genre genre\n",
      "has-author author\n",
      "has-type public\n",
      "has-population population\n",
      "org-has-member musician\n",
      "movie-has-director director\n",
      "has-population population\n",
      "has-genre genre\n",
      "movie-has-director director\n",
      "has-occupation occupation\n",
      "has-author author\n",
      "has-type instance of\n",
      "is-where country\n",
      "birth-place place of birth\n",
      "from-country country of citizenship\n",
      "from-country ethnic group\n",
      "org-has-member member of\n",
      "is-member-of member of sports team\n",
      "birth-place country of citizenship\n",
      "has-edu educated at\n",
      "has-edu educated at\n",
      "is-where country\n",
      "headquarters country\n",
      "org-has-member member of\n",
      "is-where country of citizenship\n",
      "has-author author\n",
      "from-country country of citizenship\n",
      "has-type instance of\n",
      "has-author author\n",
      "is-where country\n",
      "has-child author\n",
      "has-occupation occupation\n",
      "birth-place place of birth\n",
      "birth-place place of birth\n",
      "is-member-of member of sports team\n",
      "birth-place place of birth\n",
      "is-where country\n",
      "has-genre genre\n",
      "is-member-of member of sports team\n",
      "has-edu educated at\n",
      "has-author author\n",
      "headquarters country\n",
      "birth-place place of death\n",
      "is-member-of member of sports team\n",
      "is-where country\n",
      "from-country languages spoken or written\n",
      "has-occupation occupation\n",
      "org-has-member musician\n",
      "is-where country\n",
      "has-population population\n",
      "headquarters headquarters location\n",
      "won-award award received\n",
      "from-country country of citizenship\n",
      "has-author author\n",
      "has-type instance of\n",
      "has-genre genre\n",
      "from-country country of citizenship\n",
      "has-edu educated at\n",
      "has-population population\n",
      "has-type instance of\n",
      "org-has-member brother\n",
      "no_relation brother\n",
      "birth-place place of birth\n",
      "has-sibling sister\n",
      "movie-has-director director\n",
      "has-sibling sister\n",
      "birth-place place of birth\n",
      "has-type instance of\n",
      "has-spouse sister\n",
      "has-edu educated at\n",
      "has-type instance of\n",
      "has-occupation occupation\n",
      "org-has-member member of\n",
      "has-author author\n",
      "from-country country of citizenship\n",
      "event-year inception\n",
      "has-occupation occupation\n",
      "has-occupation occupation\n",
      "org-has-member member of\n",
      "birth-place place of birth\n",
      "has-author author\n",
      "from-country ethnic group\n",
      "has-type instance of\n",
      "has-type record label\n",
      "is-where country\n",
      "headquarters headquarters location\n",
      "org-has-founder founder\n",
      "org-has-member member of\n",
      "has-occupation employer\n",
      "is-where country\n",
      "org-has-member vocalist\n",
      "has-type organization\n",
      "has-author author\n",
      "org-has-member member of\n",
      "has-occupation occupation\n",
      "has-parent father\n",
      "has-occupation occupation\n",
      "has-author author\n",
      "from-country country of citizenship\n",
      "birth-place place of death\n",
      "headquarters headquarters location\n",
      "has-type instance of\n",
      "has-author author\n",
      "is-where country\n",
      "has-occupation occupation\n",
      "has-edu educated at\n",
      "has-author author\n",
      "has-genre genre\n",
      "has-occupation occupation\n",
      "has-author author\n",
      "org-has-member vocalist\n",
      "has-genre genre\n",
      "has-population population\n",
      "has-author author\n",
      "has-occupation occupation\n",
      "from-country nationality\n",
      "has-type instance of\n",
      "birth-place place of birth\n",
      "movie-has-director director\n",
      "has-edu educated at\n",
      "birth-place place of birth\n",
      "has-genre genre\n",
      "is-where country\n",
      "has-spouse spouse\n",
      "is-where country of origin\n",
      "has-population population\n",
      "has-occupation occupation\n",
      "org-has-member bassist\n",
      "headquarters country\n",
      "has-type record label\n",
      "birth-place country of citizenship\n",
      "org-leader leader\n",
      "has-genre genre\n",
      "has-population population\n",
      "has-population population\n",
      "org-has-founder founder\n",
      "has-population population\n",
      "from-country nationality\n",
      "has-author artist\n",
      "has-child father\n",
      "org-has-member producer\n",
      "has-occupation occupation\n",
      "org-has-founder founder\n",
      "headquarters headquarters location\n",
      "won-award actress\n",
      "org-has-founder founder\n",
      "birth-place place of birth\n",
      "headquarters located in the administrative territorial entity\n",
      "has-population population\n",
      "is-where country\n",
      "first-product product\n",
      "from-country ethnic group\n",
      "has-sibling brother\n",
      "birth-place place of birth\n",
      "has-type instance of\n",
      "birth-place place of birth\n",
      "has-genre genre\n",
      "has-type instance of\n",
      "has-author artist\n",
      "has-type instance of\n",
      "birth-place place of birth\n",
      "has-type record label\n",
      "headquarters country\n",
      "is-where located in the administrative territorial entity\n",
      "is-where located in the administrative territorial entity\n",
      "has-population population\n",
      "has-type record label\n",
      "from-country languages spoken or written\n",
      "org-leader political party\n",
      "has-author author\n",
      "is-where country\n",
      "movie-has-director director\n",
      "birth-place place of death\n",
      "starring films director\n",
      "org-has-founder founder\n",
      "won-award participant of\n",
      "movie-has-director director\n",
      "Results saved for fr to en\n",
      "has-occupation ики оуренс и актриса и сисок относително ики оуренс и актриса и сисок относително актриса и сисок относително\n",
      "has-occupation ас влетс иоисолнител мукалн родсер актр и редринимател\n",
      "has-occupation нис тре и сенарист имет отноение к тому отноеним к тому отноеним к тому отноеним к тому отноеним к тому отноени\n",
      "has-population лтмерслеен\n",
      "has-occupation лекс и и мукант и сиска отноени ереисленн дру\n",
      "has-population ттелсдор встрии в едерално емле уренланд\n",
      "has-occupation олтер ни влетс американски киноактр акое отноение луе всео оисвает отноение between олтер ни и актор и сиска отноени\n",
      "has-occupation уран урсун влетс оиим и мукалнм релиионм критиком и равоаитником\n",
      "has-type акомо ии и кардинал и сиска отноени укаанн еред акомо ии и кардинал и сиска отноени укаанн еред акомо \n",
      "has-edu оманд еликоритании и енрии редерик етимус елли  встралии — окурсрлнкр рани — ритански сортс\n",
      "has-population ссен и 4209 имеет 4209 еловек на 31 декар 2005 ода ссен и 4209 имеет 4209 еловек на 31 декар 2005 ода ссен и 4209 име\n",
      "has-population утенрунн нем аселение составлет 589 еловек на 31 декар 2005 ода ае отноение луе всео оисает отноение between утенрунн and 5\n",
      "has-occupation алентин аала и кинореисср и сиска отноени\n",
      "has-type                                                  \n",
      "has-occupation он илл ртон и адвокат и сиска отноени ереисленн адвокатов\n",
      "has-occupation есили от  олное им есили отенер от  род 8 авуста 1958 уносрес — арентински и исански актриса есили от\n",
      "has-occupation ол оренс анар\n",
      "no_relation истрал вустила сво ерву книу устоение ри соствии директора оркскоо исаноамериканскоо института едерико де ниса\n",
      "has-population иллинсдор и 168\n",
      "has-type ата и лса 1275—1292 иранн ариеиско ентерериски 1278—1299 ата и лса 1275—1292 иранн ариеиско ентерериски 1278—1299\n",
      "has-population аоне итал аселение составлет 1203 еловек лотност населени составлет 41 елкм2\n",
      "has-type уее ерсалди и кардинал\n",
      "has-occupation ани иллер\n",
      "has-occupation од и актр и сисок относително од и актр и сисок относително од и актр и сисок относително о\n",
      "has-type мерт на нееса  — двенадат иод восмоо сеона ританскоо науноантастиескоо телесериала «октор то» тое отноение лу\n",
      "has-population твердение етраерраана  — коммуна в талии расолааетс в реионе руо в ровинии ети аселение составлет 133 еловека 2008 \n",
      "has-type оменико алкано и ардинал и сиска отноени ереисленн отноени\n",
      "has-occupation ннис лутарос — оулрн реески еве в стиле лака ре\n",
      "has-occupation инда иорентино родилас 9 марта 1958 ода в иладелии в семе италнскоо иммиранта\n",
      "has-occupation енолу и от\n",
      "has-occupation нко акурада и актриса\n",
      "has-type 4 таке ивестн как Foreigner 4 — етврт студин алом ард рокру Foreigner вуенн в 1981 оду лелом Atlantic Records ае отноение луе в\n",
      "has-occupation улвио рсини и уманист и сиска отноени ереисленн отноени\n",
      "no_relation одак редставила одаром ветну аки дл илмов и сlaд\n",
      "has-occupation мадо ерво и от и сиска отноени\n",
      "has-occupation уее мато и сенарист имет отноение к уее мато и сенарист и сисок отноени укаанн ве\n",
      "has-occupation мил ареви и ктр и сиска отноени укаанн ве\n",
      "has-occupation уис акалов и комоитор имет оитивне отноени с уис акалов и комоитор и сисок отноени с уис акалов и комо\n",
      "has-occupation ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко ветко\n",
      "has-occupation ри ир — американски кинореисср акое отноение луе всео оисает отноение between ри ир и кинореисср и сиска отноени \n",
      "has-occupation редерик улас и редактор и сиска отноени редставлен наионалнми отноеними\n",
      "has-population уарен и 3229\n",
      "has-genre итаские аки  Chinese Checkers  — стратеиеска настолна ира на 2 3 4 или 6 ироков\n",
      "has-occupation рион мси и актриса и сиска отноени ереисленн актриса\n",
      "has-occupation ала уди вросла в раоне ордаланн ала уди авала в раоне ордаланн ала уди авала в раоне ордаланн ала\n",
      "has-population иртедт\n",
      "has-population орслеен\n",
      "has-occupation рнки ннин и ореора\n",
      "has-occupation иа артон влетс анлоамериканска актриса и модел\n",
      "has-occupation и арретт и актриса и сиска отноени еред и аррет и сиска отноени еред и аррет и сиска отноени еред и \n",
      "has-occupation амон т род еве вирал датски мукалн конкурс «Danish Melodi Grand Prix 2008» и олуил вомоност редставит ани на конкурсе есни \n",
      "has-occupation уан амистеи кскои\n",
      "has-population ранер и 1494\n",
      "has-population ренла  — коммуна  в встрии в едерално емле ерн встри\n",
      "has-genre ов и тан ансет и»  — американски дневна млна оера транслировавас на телеканале NBC\n",
      "has-occupation он ентимил и актор относително актор относително актор относително актор относително актор относително актор относите\n",
      "has-occupation акн арил таке ариел  —  — рануски аритектор лен кадемии аритектор 1728 королевски аритектор 1742\n",
      "has-occupation уан анул ернал и актор и сиска отноени\n",
      "has-occupation дам ринер и оератор и сиска отноени\n",
      "has-occupation аиан анер и оератор и сиска отноени аиан анер и оератор и сиска отноени аиан анер и оератор\n",
      "has-type твердение нтон ое руа  3 нор 1820 ена встриска имери — 5 авуста 1911 амок ирер ин встри вст\n",
      "has-population                                                  \n",
      "has-occupation он иан и сенарист и сиска отноени укаваеме ве\n",
      "has-occupation лу росард\n",
      "has-population уаневии  — село в ородокском раоне вовско оласти краин аселение о ереиси 2001 ода составлло 1277 еловек\n",
      "has-genre Kyo — рануски орокруа сормированна в 1994 оду\n",
      "has-type ллииеска алактика E в соведии олос ероники акое всео оисвает отноение between NGC 4308 и е и сиска отноени укаанн\n",
      "has-type алери ковски и космонавт и сиска отноени окаваеме ве\n",
      "has-population ули вовско оласти краин аселение о ереиси 2001 ода составлло 1639 еловек ули вовско оласти краин аселение \n",
      "event-year лавна револи — ринтое в истории нанаено навание осударственноо ереворота 1688 ода в нлии в реултате котороо ков II тарт\n",
      "has-occupation он евилл и актор относително актор относително актор относително актор относително актор относително актор относите\n",
      "has-occupation ом ерер и математик и сисок относително ом ерер и математик и сисок относително ом ерер и математик и сисок отно\n",
      "has-occupation е анер влетс арааником ру Slipknot\n",
      "has-type емс акл арви и кардинал и сиска отноени емс акл арви и кардинал и сиска отноени емс акл ар\n",
      "has-occupation аан анн ои веда MTV аан анн ест оен енсилвани  — американски актр олуиви всемирну ивестност \n",
      "has-population енневан и 865\n",
      "has-occupation икола рсел и сенарист иметс отноени к тому то икола рсел и сенарист иметс отноени к тому то икола \n",
      "has-occupation ранеско арилли и актор и сисок относително арилли и актор и сисок относително актор и сисок относително арилли\n",
      "has-occupation осе елисиано и еве\n",
      "has-occupation лерт нтер родилс 3 октр 1830 ода в сслиненнаеккаре в ваии ртемер лерт нтер родилс 3 октр 1830 ода\n",
      "has-type анкорн\n",
      "has-occupation арио оес и телевиионн и отноени арио оес и телевиионн и отноени арио оес и телевиионн и отноени ари\n",
      "has-occupation насио оронел илреал и наркоарон\n",
      "has-population иммелвалд — веарски деревн расолоенна меду теелером и рреном на оре илторн  2003 оду е население составл\n",
      "has-genre орд ирин лерт ирин таке ерин  ондон — орк Lentaru ука  орке умер ианиствиртуо орд \n",
      "has-occupation он аи и сенарист имет отноение к тому то он аи и сенарист имет отноение к тому то он аи и сенари\n",
      "has-population аненалведел и 186\n",
      "has-occupation ллен ир и сенарист и сисок отноени ереисср\n",
      "has-occupation  реер и актор и сиска отноени укаанн ве\n",
      "has-occupation тт акко ивестен на икла «олиеска академи» 1988—1989 а таке в оскароносном илме «екрет оснделеса» 1997\n",
      "has-type ено ратини  род итулрн ариеиско отриан с 7 авуста 1993 акое отноение луе всео оисает отноение between ено ратини and \n",
      "has-population еиор и 182\n",
      "has-occupation ри ааев и кинореисср и сиска отноени ааев и кинореисср и сиска отноени ааев и кинореисср\n",
      "has-type оллсос л и 24 влтс относителнми отноеними к оллсос л и 24 относителнми отноеними к оллсос л\n",
      "has-occupation ио ули и сенарист и исла ули и исла ули и исла ули и исла ули и исла ули и исла ули и\n",
      "has-type ла де евилла 2о арона евилла и и и лис дли\n",
      "has-type ол ндерсон ринлс на арен руи в соавторстве с которми воследствии содал несколко роиведени тое отноение луе всео оиса\n",
      "has-population идерндореререр\n",
      "event-year твердение адс ристиансен  род адс ристиансен наал роессионалну кареру в 2004 оду в клуе адс ристиансен наал \n",
      "has-occupation илм укас истант анл William Lucas Distant 12 нор 1845 18451112 — 4 еврал 1922 — анлиски нтомоло\n",
      "no_relation олт оил сво второ мирово рекорд на 100 метров  969 с 958 секунд в 2009 оду  самое олое улуение с времени наала лектронноо тамина\n",
      "has-genre аоло одо влетс аоло одо и тено и сисок отноени аоло одо и тено и сисок отноени аоло одо и те\n",
      "has-occupation уан акавеев и сенарист акавеев влтс относителми к тому отноени к тому отноени к тому отноени к тому отноени\n",
      "has-type твердение тен уровника — комлекс ооронителн сооруени вокру историеско асти орода строилис на ротении XIIXVII вв\n",
      "has-occupation амила иат и еминистка то то оисвает отноение меду амила иат и еминистка и сисок отноени которе ли редставлен \n",
      "has-occupation ернер ртер и сенарист иметс отноени к тому отноени о отноени к тому отноени к тому отноени к тому отноени к \n",
      "has-type илосердие ород од наванием илосердие ород од наванием илосердие ород од наванием илосердие ород од наванием илосерди\n",
      "has-population амтник уитм олкам адневко  — село в мине оилно оиленскоо овта увскооморскоо воеводства оли\n",
      "has-type Cole World The Sideline Story и алом и сисок относително аео отноени к аео отноени к аео отноени к аео отноени к а\n",
      "has-occupation ардан ветисн и актриса и сиска отноени ветисн и актриса и сиска отноени ветисн и актриса и сиска отноени\n",
      "has-genre монд котт и да\n",
      "has-type лдара\n",
      "has-type динауен\n",
      "event-year реми рмми а луи рокалом вруаетс на ееодно еремонии в \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 220\u001b[0m\n\u001b[1;32m    216\u001b[0m             df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 200\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m tgt_query \u001b[38;5;241m=\u001b[39m l2_query_instruct[lang2]\u001b[38;5;241m.\u001b[39mformat(e1,e2)\n\u001b[1;32m    198\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_template_cross[lang1]\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(choices), eg,crt_statement,tgt_query)\n\u001b[0;32m--> 200\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Clean the result\u001b[39;00m\n\u001b[1;32m    202\u001b[0m result \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[!@#$\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m^&*()_+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m-=[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:,.<>/?\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m|~]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[7], line 111\u001b[0m, in \u001b[0;36minference\u001b[0;34m(prompt, max_new_tokens, temperature)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# For removal of input string from the output string\u001b[39;00m\n\u001b[1;32m    109\u001b[0m input_ids_cutoff \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39msize(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;66;43;03m# top_p = 1,\u001b[39;49;00m\n\u001b[1;32m    114\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m completion \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m    120\u001b[0m generated_ids[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    121\u001b[0m skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1693\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1685\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1686\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1687\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1688\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1690\u001b[0m     )\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1710\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1711\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1718\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:3531\u001b[0m, in \u001b[0;36mGenerationMixin._beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3528\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m   3529\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 3531\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3532\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3535\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3539\u001b[0m         cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:1742\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1739\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1742\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:1109\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1095\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1096\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         output_attentions,\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:689\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    699\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:596\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    587\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    594\u001b[0m ):\n\u001b[1;32m    595\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 596\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    606\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:518\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    515\u001b[0m query_states \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq(hidden_states))  \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# get key/value states\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m value_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    522\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, key_value_states, past_key_value[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    523\u001b[0m )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# compute scores\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:502\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[0;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key_value_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# self-attn\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;66;03m# (batch_size, n_heads, key_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m past_key_value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m key_value_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;66;03m# checking that the `sequence_length` of the `past_key_value` is the same as\u001b[39;00m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;66;03m# the provided `key_value_states` to support prefix tuning\u001b[39;00m\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;66;03m# cross-attn\u001b[39;00m\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    508\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m shape(proj_layer(key_value_states))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Script for creating a prompt for the user to enter a number\n",
    "import json\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# XGLMTokenizer, XGLMForCausalLM,\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "relations = set()\n",
    "\n",
    "dir_path=\"\"\n",
    "prompt_template_cross = {\n",
    "    \"en\": \"\"\"Consider a domain where only the following relations can exist between any two entities:\n",
    "\n",
    "{}\n",
    "\n",
    "Given the following examples,\n",
    "\n",
    "{}\n",
    "\n",
    "{}\n",
    "\n",
    "{}\n",
    "    \"\"\",\n",
    "    \"fr\":\"\"\"Considérez un domaine où seules les relations suivantes peuvent exister entre deux entités : \n",
    "\n",
    "{}\n",
    "\n",
    "Étant donné les exemples suivants,\n",
    "\n",
    "{}\n",
    "\n",
    "{}\n",
    "\n",
    "{}\n",
    "    \"\"\",\n",
    "    \"ru\":\"\"\"Рассмотрим область, где могут существовать только следующие отношения между любыми двумя сущностями: \n",
    "\n",
    "{}\n",
    "\n",
    "Учитывая следующие примеры,\n",
    "\n",
    "{}\n",
    "\n",
    "{}\n",
    "\n",
    "{}\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "statements={\n",
    "    \"en\":\"Statement\",\n",
    "    \"fr\":\"Déclaration\",\n",
    "    \"ru\":\"Утверждение\"\n",
    "}\n",
    "\n",
    "decs_relation = {\n",
    "    \"en\":\"{} best describes the relation between {} and {}\",\n",
    "    \"fr\":\"{} décrit le mieux la relation entre {} et {}\",\n",
    "    \"ru\":\"{} лучше всего описывает отношение между {} и {}\"\n",
    "}\n",
    "\n",
    "l2_query_instruct={\n",
    "    \"en\":\"What relation best describes the relation between {} and {} from the list of relations given above?\",\n",
    "    \"fr\":\"Quelle relation décrit le mieux la relation entre {} et {} à partir de la liste des relations données ci-dessus?\",\n",
    "    \"ru\":\"Какое отношение лучше всего описывает отношение между {} и {} из списка отношений, указанных выше?\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def create_examples(src, tgt, num):\n",
    "    with open(dir_path + f\"{src}_corpora_train.tsv\", \"r\") as f:\n",
    "        reader = list(csv.reader(f, delimiter=\"\\t\"))\n",
    "        random.shuffle(reader)\n",
    "        examples = \"\"\n",
    "        for i, row in enumerate(reader):\n",
    "            if i < 1:\n",
    "                continue\n",
    "            if i > num:\n",
    "                break\n",
    "            sen = row[4]\n",
    "            sen = sen.replace(\"<e1>\", \"\").replace(\"</e1>\", \"\").replace(\"<e2>\", \"\").replace(\"</e2>\", \"\")\n",
    "            e1 = row[4].split(\"<e1>\")[1].split(\"</e1>\")[0]\n",
    "            e2 = row[4].split(\"<e2>\")[1].split(\"</e2>\")[0]\n",
    "            e1=\"{{\"+e1+\"}}\"\n",
    "            e2=\"{{\"+e2+\"}}\"\n",
    "            sen = \"{{\"+sen+\"}}\"\n",
    "            rel = \"{{\"+SMILER_TRANSLATE[src][row[3]]+\"}}\"\n",
    "            relations.add(rel)\n",
    "\n",
    "            rel_decs = decs_relation[src].format(rel,e1,e2)\n",
    "            examples += \"{}: {}\\n{}\\n\\n\".format(statements[src],sen,rel_decs)\n",
    "\n",
    "        return examples\n",
    "\n",
    "\n",
    "\n",
    "def inference(prompt, max_new_tokens=args.max_new_tokens, temperature=args.temperature):\n",
    "\n",
    "\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(args.device)\n",
    "\n",
    "    # For removal of input string from the output string\n",
    "    input_ids_cutoff = model_inputs.input_ids.size(dim=1)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs,\n",
    "                                   max_new_tokens=max_new_tokens,\n",
    "                                   top_p = 1,\n",
    "                                   temperature = temperature,\n",
    "                                   # num_beams=5,\n",
    "                                   do_sample=True,\n",
    "                                   pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    completion = tokenizer.decode(\n",
    "    generated_ids[0],\n",
    "    skip_special_tokens=True)\n",
    "\n",
    "    return completion\n",
    "\n",
    "\n",
    "def create_rel_vocab(src_lang, tgt_lang, src_num, tgt_num):\n",
    "\n",
    "\n",
    "    # Iterate src\n",
    "    # with open(dir_path + f\"{src_lang}_corpora_train.tsv\", \"r\") as f:\n",
    "    #     reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    #     for i, row in enumerate(reader):\n",
    "    #         if i < 1:\n",
    "    #             continue\n",
    "    #         if i > src_num:\n",
    "    #             break\n",
    "    #         relations.add(f\"{row[3]}\")\n",
    "\n",
    "    # Iterate tgt\n",
    "    try:\n",
    "        with open(dir_path + f\"{tgt_lang}_corpora_test.tsv\", \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\")\n",
    "            for i, row in enumerate(reader):\n",
    "                if i < 1:\n",
    "                    continue\n",
    "                if i > tgt_num:\n",
    "                    break\n",
    "                rel = \"{{\"+SMILER_TRANSLATE[src_lang][row[3]]+\"}}\"\n",
    "                relations.add(f'{rel}')\n",
    "                # relations.add(f'\"{row[3]}\"')\n",
    "    except Exception:\n",
    "        print(src_lang, tgt_lang, row[3])\n",
    "        raise Exception()\n",
    "\n",
    "    return relations\n",
    "\n",
    "\n",
    "def main():\n",
    "    global relations\n",
    "    for lang1 in [args.l1, args.l2, args.l3]:\n",
    "        for lang2 in [args.l2, args.l1, args.l3]:\n",
    "            actual_result = []\n",
    "            gen_result = []\n",
    "            relations = set()\n",
    "\n",
    "            if lang1 == lang2:\n",
    "                continue\n",
    "\n",
    "            # Create relation vocabulary\n",
    "            choices = create_rel_vocab(lang1, lang2, args.src_num, args.tgt_num)\n",
    "\n",
    "            # If not zero-shot, create examples\n",
    "            eg = create_examples(lang1, lang2, args.src_num)\n",
    "\n",
    "            os.makedirs(f\"{lang1}_{lang2}\", exist_ok=True)\n",
    "            # Create prompt for each example and save it\n",
    "            with open(dir_path + f\"{lang2}_corpora_test.tsv\", \"r\") as f:\n",
    "                reader = csv.reader(f, delimiter=\"\\t\")\n",
    "                for i, row in enumerate(reader):\n",
    "                    if i < 1:\n",
    "                        continue\n",
    "                    if i > args.tgt_num:\n",
    "                        break\n",
    "                    # if f'\"{SMILER_TRANSLATE[lang2][row[3]]}\"' not in choices:\n",
    "                    # # if f'\"{row[3]}\"' not in choices:\n",
    "                    #     raise ValueError(f\"Relation {row[3]} not in the relation vocabulary {lang2}\")\n",
    "\n",
    "                    sen = row[4]\n",
    "                    sen = sen.replace(\"<e1>\", \"\").replace(\"</e1>\", \"\").replace(\"<e2>\", \"\").replace(\"</e2>\", \"\")\n",
    "                    e1 = row[4].split(\"<e1>\")[1].split(\"</e1>\")[0]\n",
    "                    e2 = row[4].split(\"<e2>\")[1].split(\"</e2>\")[0]\n",
    "                    sen = \"{{\"+sen+\"}}\"\n",
    "                    e1 = \"{{\"+e1+\"}}\"\n",
    "                    e2 = \"{{\"+e2+\"}}\"\n",
    "                    # prompt = prompt_src.format(sen, e1, e2, \"\\n\".join(choices))\n",
    "                    crt_statement = statements[lang2]+\": \"+ sen + \"\\n\"\n",
    "                    tgt_query = l2_query_instruct[lang2].format(e1,e2)\n",
    "                    prompt = prompt_template_cross[lang1].format(\"\\n\".join(choices), eg,crt_statement,tgt_query)\n",
    "                    \n",
    "                    result = inference(prompt)\n",
    "                    # Clean the result\n",
    "                    result = re.sub(r\"[!@#$%^&*()_+\\-=[\\]{};':,.<>/?\\\\|~]\", \"\", result)\n",
    "                    # Also remove all quotes\n",
    "                    result = result.replace('\"', \"\").replace(\"'\", \"\").replace(\"`\", \"\")\n",
    "                    # result = next((key for key, value in SMILER_TRANSLATE[lang2].items() if value == result), result)\n",
    "\n",
    "                    print(row[3], result)\n",
    "                    \n",
    "                    with open(f\"{lang1}_{lang2}/prompt_{i}.txt\", \"w\") as f:\n",
    "                        f.write(prompt)\n",
    "\n",
    "                    actual_result.append(SMILER_TRANSLATE[lang1][row[3]])\n",
    "                    gen_result.append(result)\n",
    "\n",
    "            df = pd.DataFrame({\"actual\": actual_result, \"generated\": gen_result})\n",
    "            df.to_csv(f\"{lang1}_{lang2}/results.tsv\", sep=\"\\t\", index=False)\n",
    "            print(f\"Results saved for {lang1} to {lang2}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OjKr0IL4wLT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AY3JXZuf5c1j"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0117f2e9046345a5b40027edfac7f720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35ea4b05b4b846dba3ec8f02187bcf74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e0fc85e27943c99a2b5638847162ba",
      "placeholder": "​",
      "style": "IPY_MODEL_c048ce12b86d43f3a7f73d57206af54b",
      "value": "Loading checkpoint shards:   0%"
     }
    },
    "59e0fc85e27943c99a2b5638847162ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "687c6b1edf7c4c1f904cf05781bbcb7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e00260ebab7a417c8b11a0258be7639e",
      "placeholder": "​",
      "style": "IPY_MODEL_0117f2e9046345a5b40027edfac7f720",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "86a3b5428b6e4cfead4ac4881f3fadc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8abc87c740f843579b5442588ec0310d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86a3b5428b6e4cfead4ac4881f3fadc0",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e48625d8fd7748f29fc24eff45ebedc7",
      "value": 0
     }
    },
    "94eb1b7347ff452f80c9065d51073b97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c048ce12b86d43f3a7f73d57206af54b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf1d2483bfa940c99cd6d1c1bb2102f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35ea4b05b4b846dba3ec8f02187bcf74",
       "IPY_MODEL_8abc87c740f843579b5442588ec0310d",
       "IPY_MODEL_687c6b1edf7c4c1f904cf05781bbcb7d"
      ],
      "layout": "IPY_MODEL_94eb1b7347ff452f80c9065d51073b97"
     }
    },
    "e00260ebab7a417c8b11a0258be7639e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e48625d8fd7748f29fc24eff45ebedc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
